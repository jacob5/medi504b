---
title: "Building a Predictive Machine Learning Model to Identify Polycystic Ovary Syndrome Using Easily Measured Clinical or Physiological Parameters"
author: "Jacob and Hanwei"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

``` {r libraries, echo=FALSE, message=FALSE, warning = FALSE, results = "hide"}
# loading libraries

library(tidyverse)
library(ggplot2)
library(scales)
library(finalfit)
library(patchwork)
library(readr)
library(epiR)
library(readxl)
library(gridExtra)
library(janitor)
library(ranger)
library(xgboost)
library(DataExplorer)
library(caret)

# install.packages("DataExplorer")

# install.packages("janitor")

# install.packages("ranger")

# install.packages("xgboost")


```

## 1. Introduction and Background

### 1.1 Introduction
Our overarching goal for this project is to produce a machine learning (ML) model which can accurately predict polycystic ovary syndrome (PCOS) status (presence or absence of disease) using predictors easily derived from a standard blood test and routine clinical examination. PCOS is an endocrine (hormonal) disorder that affects females of a reproductive age^1^. Given the widespread nature of this condition among women of reproductive age and the troubling symptoms which accompany it, including infertility, it would be helpful for physicians to be able to predict, using just blood test results and a routine clinical exam, individuals more likely to experience PCOS thereby enabling them to therapeutically intervene and provide care and support in a timely manner, especially considering PCOS has been associated with other conditions such as endometriosis and endometrial cancer^2,5^. 

### 1.2 Background 

Polycystic ovarian syndrome (PCOS) is a common endocrine disorder affecting approximately 10-15% of reproductive-age women worldwide^1^. The condition is characterized by a complex set of symptoms, including hyperandrogenism, menstrual irregularities, and polycystic ovaries^2^. The diagnosis of PCOS is typically based on clinical and biochemical assessments, as well as ultrasound imaging of the ovaries^1^. However, the diagnosis of PCOS can be challenging due to the heterogeneous presentation of symptoms and the lack of a single diagnostic criterion.

Machine learning models have shown promise as a potential tool for the accurate prediction of PCOS. Compared to traditional diagnostic methods, machine learning models can utilize large amounts of data from various sources and provide more accurate predictions. This is particularly beneficial in the case of PCOS, as traditional diagnostic methods such as tissue biopsy or ultrasound imaging can be expensive and invasive. Furthermore, machine learning models can assist clinicians in identifying patients who may benefit from early intervention, which can improve long-term health outcomes (Teede et al., 2018).

Our aim for this PCOS predictive model would be to assist clinicians with identifying women between the ages of 21-47 at highest risk or likely to develop PCOS. Moreover, we hope this predictive model may be used in both low and high resource settings, and we are therefore limiting the features used by the model to clinical and physiological parameters easily obtained via a routine clinical exam and standard blood test. 

To ensure out analysis is ethical, the appropriate ethical approval was obtained for this ML project. To help ensure privacy fo this ML project, we worked with de-identified anonymized data. In the event an individual was identified as being pregnant or may be at risk of a life-threatening condition, we would follow-up immediately with the individual's physician. 

The rationale for developing this predictive ML model is based on the motivation to provide a data-based method of diagnosis that is cheaper and less invasive than current methods, a method which may be applied without expensive diagnostic equipment (such as an ultrasound imaging device), a method which may be used with just a blood test and the review of clinical symptoms and a method which relies minimally on self-reported data. As discussed in the background section of this report, current diagnosis of PCOS can be time-consuming and invasive, and replacing these methods with a model is advantageous for reasons related to clinical care and resource utilization. This influenced our variable selection, as we did not consider the inclusion of predictors that can not be measured in the above stated context in model development. 

Overall, the use of machine learning models to predict PCOS has the potential to improve the accuracy of diagnosis and reduce the cost and invasiveness of traditional diagnostic methods. We sought to evaluate the comparative accuracy of multiple machine learning classifiers to select the optimal model for predicting PCOS based on variables obtained via a blood test and routine clinical examination, given considerations surrounding false positive and false negatives. 

### 1.3 Data

The dataset consists of physical and clinical parameters collected from 10 hospitals across Kerala, India, to determine PCOS and infertility-related issues. The dataset contains information that can be used to analyze and understand the diagnosis and treatment of PCOS and infertility.

## 2. Objectives

Our objectives were twofold: 

1: Develop a simple model that can predict PCOS status using clinical and physiologic data that can be acquired using a routine blood test and assessment by a general practitioner clinician. 

2: Optimize the model for specificity, thus minimizing the risk of a false positive in model predictions. 

Optimizing model specificity for the prediction of PCOS is important because PCOS is associated with several negative health outcomes, including infertility, insulin resistance, and metabolic disorders. Early diagnosis and treatment of PCOS can help prevent or manage these conditions, which can ultimately improve the overall health and quality of life of those affected. However, given that PCOS is not a life-threatening condition in and of itself, it is important to balance the trade-off between maximizing sensitivity and specificity in order to minimize the number of false positives and prevent unnecessary and potentially invasive follow-up testing. By optimizing model specificity, we can ensure that those who are diagnosed with PCOS are more likely to truly have the condition, while also reducing the risk of unnecessary medical interventions for those who do not have PCOS.

## 3. Methods

### 3.1 Splitting our dataset into training and testing datasets
Following our Exploratory Data Analysis (EDA, please refer to Results section for EDA), we start by splitting our dataset into the training set and the validation set, followed by building a simple model aimed at using our data to find factors that predict PCOS status (our outcome variable). We chose to partition our data into only two sets based on the relatively small overall sample size of our data and small effective sample size of our data. Further, to help determine generalizability, we believe it would be ideal for our predictive model to be validated on an external dataset derived from a different population than our training and test data.  

### 3.2 Variable selection and building logistic regression models 

We first attempted to model our data with PCOS status as the outcome variable using three different logistic regression models. At this stage of variable selection, we undertook a combined approach to informing variable selection. The Akaike Information Criteria (AIC) was used to assess model fit, the Area Under the Receiving Operator Characteristic (AUC) was used to assess model accuracy, and the model with the best balance between both of these parameters, as well as clinical utility was used. The three tested models utilized the following construction:

* (1) Model 1 is the physiological model which includes five hormones of interest, namely hormone measurements of n=5 different types of hormones commonly included or easily measured as a part of a standard routine blood test.
* (2) Model 2 is the clinical model, including as variables clinical symptoms associated with PCOS, and specifically clinical symptoms which may be easily determined as a part of a routine examination by a physician. THese are the variables included in the clinical model: weight gain, hair growth + skin darkening, hair loss and pimples.
* (3) Model 3 includes both the physiological and clinical variables, that is the n=5 the hormone measurement levels we as well as the clinical symptoms that have been known to be associated with PCOS: weight gain, hair growth + skin darkening, hair loss and pimples (clinical symptoms which may be easily identified or tracked in a basic clinical setting). 

Following this initial variable selection, we selected the two best performing models and applied various machine learning training methods to optimize model performance. We then selected the best performing model as the final model. 

Of our three logistic regression models, Model 2 had the lowest AIC score of 317, followed by Model 3 with an AIC score of 566. However, the predictive performance as assesed by AUC was higher for model 3 (0.99) than model 2 (0.88). While model 3 was better performing, it also required more parameters for prediction that require blood testing. The rationale for testing both models with machine learning optimization was to assess if a simpler model with clinical parameters only could approximate the classification performance of a more complex model. 

## Results 

## 4. Results

## 4a. Exploratory Data Analysis
This section contains the steps and output for the EDA performed on the PCOS dataset. The section proceeds sequentially with each step of EDA. Please refer to bullet points, figure titles and figure captions for more details. The first steps in our EDA involved getting a high-level overview of our dataset and determining the dimension of our data: n=541 rows and n=45 columns. Further checking of the dataset reveals an additional column (column 45). This column does not contain any useful information and is not one of our 44 features, therefore the column was removed. We find that our dataset has the following variables: Sl. No, Patient File No., PCOS (Y/N), Age (yrs), Weight (Kg), Height(Cm), BMI, Blood Group, Pulse rate(bpm), RR(breaths/min), Hb(g/dl), Cycle(R/I), Cycle length(days), Marriage Status (Yrs), Pregnant(Y/N), No. of aborptions, I   beta-HCG(mIU/mL), II    beta-HCG(mIU/mL), FSH(mIU/mL), LH(mIU/mL), FSH/LH, Hip(inch), Waist(inch), Waist:Hip Ratio, TSH (mIU/L), AMH(ng/mL), PRL(ng/mL), Vit D3 (ng/mL), PRG(ng/mL), RBS(mg/dl), Weight gain(Y/N), hair growth(Y/N), Skin darkening (Y/N), Hair loss(Y/N), Pimples(Y/N), Fast food (Y/N), Reg.Exercise(Y/N), BP _Systolic (mmHg), BP _Diastolic (mmHg), Follicle No. (L), Follicle No. (R), Avg. F size (L) (mm), Avg. F size (R) (mm), Endometrium (mm).

``` {r loading, echo=FALSE, message=FALSE, warning = FALSE, results = "hide"}
# loading data
# setwd("/Users/hanweisudderuddin/Desktop/MSc Stuff/Classes/MEDI504B/Week1_lab_EDA")
setwd(here::here())
# PCOS_infertility <- read_csv("PCOS_infertility.csv")
data_loc <- here::here()
# reading in PCOS_data_without_infertility from excel file
PCOS_data_without_infertility <-read_excel(paste0(data_loc, "/PCOS_data_without_infertility.xlsx"), sheet = "Full_new")
# PCOS_infertility <- read_csv("PCOS_infertility.csv")



# glimpse(PCOS_data_without_infertility)

# view(PCOS_data_without_infertility)

# summary(PCOS_data_without_infertility)

```

```{r cleaning, echo=FALSE, fig.height=10, fig.width=20, message=FALSE, warning=FALSE, results= "hide"}
## checking and cleaning dataset 
unique(PCOS_data_without_infertility$...45)

## removing column "...45" to clean dataset

PCOS_data_without_infertility <- PCOS_data_without_infertility %>%
                                    select(-...45)

# glimpse(PCOS_data_without_infertility)

# view(PCOS_data_without_infertility)

## cleaning variable names with janitor package

PCOS_data_without_infertility_cleaned <- PCOS_data_without_infertility %>%
                                          clean_names()

# glimpse(PCOS_data_without_infertility_cleaned)

```

### 4a.1 Data Wrangling

The data was formatted to ensure the variables are the appropriate class type, this will enable us to perform our EDA. Specifically we converted binary variables (1 or 0) into the character class type.Next in our EDA we sought to identify missing values in our dataset. Here, we see a plot showing our variables and the percentage of missing rows per variable. The plot shows the missing values in our dataset. Our EDA identified some missing values for two variables: fast food and marriage status. The analysis indicates that only 0.18% of the rows for these variables are missing. Therefore, as this is below the generally used threshold of 5 %, missing values were simply removed for our subsequent analyses. 

```{r formatting, echo=FALSE, fig.height=10, fig.width=20, message=FALSE, warning=FALSE, results="hide"}
## ensuring variables are in the correct format 

PCOS_data_without_infertility_formatted <- PCOS_data_without_infertility_cleaned %>%
                                              mutate_at(c("sl_no",
                                                          "patient_file_no",
                                                          "pcos_y_n",
                                                          "weight_gain_y_n", 
                                                          "hair_growth_y_n",
                                                          "hair_growth_y_n",
                                                          "skin_darkening_y_n",
                                                          "hair_loss_y_n",
                                                          "pimples_y_n",
                                                          "fast_food_y_n",
                                                          "reg_exercise_y_n"), as.character)%>%
  mutate_at(c(
    "i_beta_hcg_m_iu_m_l",
    "fsh_m_iu_m_l" ,
    "lh_m_iu_m_l" ,
    "tsh_m_iu_l" ,
    "amh_ng_m_l"), as.numeric)

# glimpse(PCOS_data_without_infertility_formatted)

```


### 4a.2 Bivariate associations 

We examined associations for categorical predictors and the outcome (PCOS) by constructing bivariate plots for the predictors stratified by PCOS status^4^. 

```{r EDA4, echo=FALSE, fig.height=10, fig.width=20, message=FALSE, warning=FALSE, results= "hide"}
# plotting bar plots for each categorical feature
plot_bar(PCOS_data_without_infertility_formatted, by = "pcos_y_n", title = "Barplots for the categorical variables in our dataset")

```

From the figure, we can see that the proportion of individuals with weight gain and a positive PCOS status is greater than the proportion of individuals with no weight gain and a positive PCOS status. We observe similar associations for hair growth and skin darkening. We also observe a similar but much weaker association for the categorical variables of hair loss and pimples. Interestingly, we observe the inverse trend for the categorical variable for fast food consumption. As these predictors appear to be visually associated with the outcome, as well as physiologically feasible to be associated with PCOS, they should be considered for inclusion in the predictive model. 

The bar plots for regular exercise and pregnancy do not appear to show a significant difference in proportion of positive PCOS cases, but we would need to perform a statistical analyses (such as an unpaired t-test) to know for sure. 
To ascertain the relationship between PCOS status and continuous predictors, we also plotted boxplots to visualize any associations between PCOS status and a continuous variable. Please refer to the appendix for these boxplots.

For this section of the EDA, we looked more closely at the relationships between selected variables and our outcome variable of interest (for this project: yes or no for PCOS), based on how our boxplots looked initially (please refer to Appendix for all boxplots) and on some knowledge gained via our literature survey, we will highlight the relatiionship of select variables with our outcome variable (PCOS status). While the etiology for PCOS is not known, our literature survey suggests PCOS is associated with abnormal hormone levels. Thus, to look into this further as part of the EDA, we compared measurements of hormone levels and PCOS status to get a sense of the relationships between these variables.

### Boxplots looking at relationship of hormones and PCOS status
```{r hormonevariables, echo=FALSE, fig.height=10, fig.width=20, message=FALSE, warning=FALSE, results= "hide"}

## looking more closely and the relationships between selected variables and our outcome variable of interest (PCOS yes or no)

## I   beta-HCG(mIU/mL) hormone 

# glimpse(PCOS_data_without_infertility_formatted)

eda_compare_plot1 <- PCOS_data_without_infertility_formatted %>%
                        ggplot(aes(pcos_y_n, i_beta_hcg_m_iu_m_l)) + 
                        geom_boxplot() +
                        theme_bw() +
                        theme(title = element_text(size = 22),
                              plot.caption = element_text(hjust = 0, size = 20)) +
                        labs(title = "Beta-HCG and PCOS status") + scale_y_log10() 

# eda_compare_plot1


## follicle stimulating hormone

eda_compare_plot2 <- PCOS_data_without_infertility_formatted %>%
                        ggplot(aes(pcos_y_n, fsh_m_iu_m_l)) + 
                        geom_boxplot() +
                        theme_bw() +
                        theme(title = element_text(size = 22),
                              plot.caption = element_text(hjust = 0, size = 20)) +
                        labs(title = "Follicle stimulating hormone and PCOS status") +
                        scale_y_log10()

# eda_compare_plot2


## luteinizing hormone

eda_compare_plot3 <- PCOS_data_without_infertility_formatted %>%
                        ggplot(aes(pcos_y_n, lh_m_iu_m_l)) + 
                        geom_boxplot() +
                        theme_bw() +
                        theme(title = element_text(size = 22),
                              plot.caption = element_text(hjust = 0, size = 20)) +
                        labs(title = "Luteinizing hormone and PCOS status") +
                        scale_y_log10()

# eda_compare_plot4

## Thyroid Stimulating Hormone

eda_compare_plot4 <- PCOS_data_without_infertility_formatted %>%
                        ggplot(aes(pcos_y_n,tsh_m_iu_l)) + 
                        geom_boxplot() +
                        theme_bw() +
                        theme(title = element_text(size = 22),
                              plot.caption = element_text(hjust = 0, size = 20)) +
                        labs(title = "Thyroid Stimulating Hormone and PCOS status") +
                        scale_y_log10()

# eda_compare_plot4


cowplot::plot_grid(eda_compare_plot1, eda_compare_plot2, eda_compare_plot3, eda_compare_plot4, ncol=2, nrow=2)
```

To get a sense of the variation in our dataset, we plotted histograms for each continuous variable using the plot_histogram() from the DataExplorer Package. We see that the age distribution in our dataset reveals most individuals are in the range of 20 to 40 years. No individuals in the dataset are younger than 20 or older than 50. As we would expect, the BMI values follow an approximately normal distribution. The most common blood type we observe is O+, which is consistent with the fact that O+ is the most frequent bloodtype globally. The most common cycle length is 5 days. The endometrium thickness data suggests there are two most most common thickness values (two clear peaks in the distribution).

### Modelling

```{r methods, echo=FALSE, message=FALSE, warning = FALSE, results = "hide"}

# loading data
# setwd("/Users/hanweisudderuddin/Desktop/MSc Stuff/Classes/MEDI504B/Week1_lab_EDA")
setwd(here::here())
# PCOS_infertility <- read_csv("PCOS_infertility.csv")
data_loc <- here::here()
# reading in PCOS_data_without_infertility from excel file
PCOS_data_without_infertility <-read_excel(paste0(data_loc, "/PCOS_data_without_infertility.xlsx"), sheet = "Full_new")

## checking and cleaning dataset 
unique(PCOS_data_without_infertility$...45)

## removing column "...45" to clean dataset

PCOS_data_without_infertility <- PCOS_data_without_infertility %>%
                                    select(-...45)

# glimpse(PCOS_data_without_infertility)

# view(PCOS_data_without_infertility)

## cleaning variable names with janitor package

PCOS_data_without_infertility_cleaned <- PCOS_data_without_infertility %>%
                                          clean_names()

glimpse(PCOS_data_without_infertility_cleaned)

PCOS_data_without_infertility_formatted <- PCOS_data_without_infertility_cleaned %>%
                                              mutate_at(c("sl_no",
                                                          "patient_file_no",
                                                          "pcos_y_n",
                                                          "weight_gain_y_n", 
                                                          "hair_growth_y_n",
                                                          "hair_growth_y_n",
                                                          "skin_darkening_y_n",
                                                          "hair_loss_y_n",
                                                          "pimples_y_n",
                                                          "fast_food_y_n",
                                                          "reg_exercise_y_n"), as.factor)%>%
    mutate_at(c(
    "i_beta_hcg_m_iu_m_l",
    "fsh_m_iu_m_l" ,
    "lh_m_iu_m_l" ,
    "tsh_m_iu_l" ,
    "amh_ng_m_l"), as.numeric)

glimpse(PCOS_data_without_infertility_formatted)

PCOS_data_without_infertility_formatted_final <- PCOS_data_without_infertility_formatted %>%
                                              drop_na()

unique(PCOS_data_without_infertility_formatted_final$pcos_y_n)

# changing outcome variable to factor class 
PCOS_data_without_infertility_formatted_final$pcos_y_n <- as.factor(PCOS_data_without_infertility_formatted_final$pcos_y_n)
```

```{r, data split, echo=FALSE, message=FALSE, warning = FALSE, results = "hide"}
#####
## setting the seed (enables randomization in a reproducible way)
set.seed(504)

data_split <- caret::createDataPartition(PCOS_data_without_infertility_formatted_final$pcos_y_n, p=0.7, list= FALSE)

train.data <- PCOS_data_without_infertility_formatted_final[data_split,]
# dim(train.data)
test.data <- PCOS_data_without_infertility_formatted_final[-data_split,]
# dim(test.data)

# table(train.data$pcos_y_n)

# the first model we will build will include all the variables 
#library(glmnet)

logistic_model1 <- glm(pcos_y_n ~amh_ng_m_l+
                                                
                                                                           i_beta_hcg_m_iu_m_l +
 lh_m_iu_m_l + 

                         fsh_m_iu_m_l + 
                          tsh_m_iu_l

                                           ,
                       data = train.data,
                       family = binomial(link="logit")) 


# AIC = 758
# removed this as not super informative for logistic models 
# plot(logistic_model1)

library(broom)

# the second model uses clinical data only

logistic_model2 <-glm(pcos_y_n ~ 
                          weight_gain_y_n +
                         hair_growth_y_n +
                         skin_darkening_y_n +
                         hair_loss_y_n +
                         pimples_y_n,
                      data = train.data,
                      family = binomial(link="logit"))


# AIC = 609.28

# glimpse(PCOS_data_without_infertility_formatted_final)

# the third model we will build will include the following variables:
# 5 of the hormone measurement levels we possess
# as well as the following physiological variables (as these are clinical symptoms associated with PCOS): 

logistic_model3 <- glm(pcos_y_n ~ 
                         i_beta_hcg_m_iu_m_l +
                         fsh_m_iu_m_l + 
                         lh_m_iu_m_l + 
                         tsh_m_iu_l +
                         amh_ng_m_l +
                         weight_gain_y_n +
                         hair_growth_y_n +
                         skin_darkening_y_n +
                         hair_loss_y_n +
                         pimples_y_n,
                       data = train.data,
                       family = binomial(link="logit"))


# AIC = 566.45

auc1 <- pROC::roc(train.data$pcos_y_n,
                   fitted(logistic_model1))
tidyr::extract_numeric(auc1$auc)
auc2 <- pROC::roc(train.data$pcos_y_n,
                   fitted(logistic_model2))
tidyr::extract_numeric(auc2$auc)
auc3 <- pROC::roc(train.data$pcos_y_n,
                   fitted(logistic_model3))
tidyr::extract_numeric(auc3$auc)

knitr::kable(data.frame("Model"=c("Physiologic Model", "Clinical Model", "Physiologic and Clinical Model"),
           "AIC"=c(logistic_model1$aic, logistic_model2$aic, logistic_model3$aic), 
           "ROC"=c(tidyr::extract_numeric(auc1$auc), tidyr::extract_numeric(auc2$auc), tidyr::extract_numeric(auc3$auc)
)))
# 
# BIC(logistic_model1)
# BIC(logistic_model2)
# BIC(logistic_model3)


```

Based on these results, we will compare the clinical model to the full clinical and physiological model. While the model including clinical predictors only is more simple both technically (as evidenced by the AIC) and practically (less inputs and no blood testing required), there is an approximately 10% drop in accuracy when excluding the physiological data. We will select these two models and compare performance in applying various machine learning methods below. 

### 3.3 Assessing model classification performance 
* Assessing model performance using ROC curves 

```{r echo=FALSE, fig.height=6, fig.width=4, message=FALSE, warning=FALSE}
## plotting ROC and AUC 

# plot(pROC::roc(train.data$pcos_y_n,
#                    fitted(logistic_model1)),
#                col = "red", 
#                main = "ROC curves: model 1 (red) vs. model 2 (blue) \n vs. model 3 (green)")
plot(pROC::roc(train.data$pcos_y_n,
                   fitted(logistic_model2)),
               print.auc = T, 
               col = "blue",
                main = "ROC curves: clinical model (blue) \n vs. clinical and physiologic model (green)",
                print.auc.y = .6)
plot(pROC::roc(train.data$pcos_y_n,
                   fitted(logistic_model3)),
               print.auc = T, 
               col = "green", 
               add = T,
     print.auc.y=.4)

```

### 3.4 Penalized logistic regression with cross-validation (RIDGE and LASSO)

```{r echo=FALSE, message=FALSE, warning = FALSE, results = "hide"}

# glimpse(train.data)
# 
# summary(train.data)

train.data.covariates.all <- train.data %>% 
                                 mutate(pcos_y_n = ifelse(pcos_y_n == "1", "Yes", "No")) %>%
                                 drop_na()%>%
  mutate_at(c("pcos_y_n",
              "weight_gain_y_n", 
              "hair_growth_y_n",
              "skin_darkening_y_n",
              "hair_loss_y_n",
              "pimples_y_n"),as.factor) %>%
  mutate_at(c(
    "i_beta_hcg_m_iu_m_l",
    "fsh_m_iu_m_l" ,
    "lh_m_iu_m_l" ,
    "tsh_m_iu_l" ,
    "amh_ng_m_l"), as.numeric) 

glimpse(train.data.covariates.all)

baselinevars_all <- names(dplyr::select(train.data.covariates.all, 
                         !c(pcos_y_n)))
baselinevars_all

model_formula_all <- as.formula(paste("pcos_y_n~ ", 
                               paste(baselinevars_all, 
                                     collapse = "+")))

model_formula_all

train.data.2 <- train.data.covariates.all %>%
                  select(pcos_y_n,
                         i_beta_hcg_m_iu_m_l,
                         fsh_m_iu_m_l,
                         lh_m_iu_m_l,
                         tsh_m_iu_l ,
                         amh_ng_m_l)%>%mutate(
                           pcos_y_n=as.factor(pcos_y_n)
                         )
  

glimpse(train.data.2)

train.data.covariates.1 <- train.data %>%
  select(
    pcos_y_n,
    i_beta_hcg_m_iu_m_l,
    fsh_m_iu_m_l,
    lh_m_iu_m_l,
    tsh_m_iu_l,
    amh_ng_m_l ,
    weight_gain_y_n ,
    hair_growth_y_n,
    skin_darkening_y_n,
    hair_loss_y_n ,
    pimples_y_n
  ) %>%
  mutate_at(c("pcos_y_n",
              "weight_gain_y_n", 
              "hair_growth_y_n",
              "skin_darkening_y_n",
              "hair_loss_y_n",
              "pimples_y_n"),as.factor) %>%
  mutate_at(c(
    "i_beta_hcg_m_iu_m_l",
    "fsh_m_iu_m_l" ,
    "lh_m_iu_m_l" ,
    "tsh_m_iu_l" ,
    "amh_ng_m_l"), as.numeric) 

# train.data.2 <- train.data.covariates.1 %>%
#                  drop_na() %>%
#                  mutate(pcos_y_n = ifelse(pcos_y_n == "1", "Yes", "No"))

glimpse(train.data.2)

train.data.3 <- train.data.covariates.1 %>%
                  drop_na() %>%
                  mutate(pcos_y_n = ifelse(pcos_y_n == "1", "Yes", "No"))

# view(train.data.1)

# summary(train.data.1)

baselinevars_3 <- names(dplyr::select(train.data.3, 
                         !c(pcos_y_n)))
baselinevars_3

model_formula_3 <- as.formula(paste("pcos_y_n~ ", 
                               paste(baselinevars_3, 
                                     collapse = "+")))

model_formula_3

## RIDGE cross-validation of our logistic regression models (with binary outcome)
set.seed(504)
ctrl<-trainControl(method = "cv", number = 5,
                   classProbs = TRUE,
                   summaryFunction = twoClassSummary)


## model 1 with all variables
fit.cv.bin.model.all <-train(model_formula_all, trControl = ctrl,
                                 data = train.data.covariates.all, method = "glmnet",
                                 lambda= 0,
                                 tuneGrid = expand.grid(alpha = 0,  
                                                        lambda = 0),
                                 verbose = FALSE,
                                 metric="ROC")
fit.cv.bin.model.all

# model 1 ROC output (RIDGE): 0.5662222

## model 2 with only hormone variables 
fit.cv.bin.model2 <-train(pcos_y_n ~ ., trControl = ctrl,
                                 data = train.data.2, method = "glmnet",
                                 lambda= 0,
                                 tuneGrid = expand.grid(alpha = 0,  
                                                        lambda = 0),
                                 verbose = FALSE,
                                 metric="ROC")
fit.cv.bin.model2

# model 2 ROC output (RIDGE): 0.6045425

## model 3 with hormone variables and clinical symptoms 
fit.cv.bin.model3 <-train(model_formula_3, trControl = ctrl,
                                 data = train.data.3, method = "glmnet",
                                 lambda= 0,
                                 tuneGrid = expand.grid(alpha = 0,  
                                                        lambda = 0),
                                 verbose = FALSE,
                                 metric="ROC")
fit.cv.bin.model3
# model 3 ROC output (RIDGE): 0.8737665

## LASSO cross-validation of our logistic regression models

set.seed(504)
ctrl<-trainControl(method = "cv", number = 5,
                   classProbs = TRUE,
                   summaryFunction = twoClassSummary)


## model 1 with all variables
fit.cv.bin.model.all.lasso <-train(model_formula_all, trControl = ctrl,
                                 data = train.data.covariates.all, method = "glmnet",
                                 lambda= 0,
                                 tuneGrid = expand.grid(alpha = 1,  
                                                        lambda = 0),
                                 verbose = FALSE,
                                 metric="ROC")
fit.cv.bin.model.all.lasso

# model 1 output (LASSO): 0.6005752

## model 2 with only hormone variables 
fit.cv.bin.model2.lasso <-train(pcos_y_n ~ ., trControl = ctrl,
                                 data = train.data.2, method = "glmnet",
                                 lambda= 0,
                                 tuneGrid = expand.grid(alpha = 1,  
                                                        lambda = 0),
                                 verbose = FALSE,
                                 metric="ROC")
fit.cv.bin.model2.lasso

# model 2 output (LASSO): 0.6286078

## model 3 with hormone variables and clinical symptoms 
fit.cv.bin.model3.lasso <-train(model_formula_3, trControl = ctrl,
                                 data = train.data.3, method = "glmnet",
                                 lambda= 0,
                                 tuneGrid = expand.grid(alpha = 1,  
                                                        lambda = 0),
                                 verbose = FALSE,
                                 metric="ROC")

fit.cv.bin.model3.lasso

# model 3 output (LASSO): 0.8756765

## Cross-validation using ElasticNet

# CV using ElasticNet (for model 1)
set.seed(504)
ctrl<-trainControl(method = "cv", number = 5,
                   classProbs = TRUE,
                   summaryFunction = twoClassSummary)

fit.cv.bin.elastic.model_1 <-train(model_formula_all, trControl = ctrl,
                                   data = train.data.covariates.all, method = "glmnet",
                                   tuneGrid = expand.grid(alpha = seq(0.1,.2,by = 0.05),  
                                                          lambda = seq(0.05,0.3,by = 0.05)),
                                   verbose = FALSE,
                                   metric="ROC")

fit.cv.bin.elastic.model_1

elastic_model1 <- plot(fit.cv.bin.elastic.model_1)

# CV using ElasticNet (for model 2) 

fit.cv.bin.elastic.model_2 <-train(pcos_y_n ~ ., trControl = ctrl,
                                   data = train.data.2, method = "glmnet",
                                   tuneGrid = expand.grid(alpha = seq(0.1,.2,by = 0.05),  
                                                          lambda = seq(0.05,0.3,by = 0.05)),
                                   verbose = FALSE,
                                   metric="ROC")

elastic_model2 <- plot(fit.cv.bin.elastic.model_2)

# CV using ElasticNet (for model 3) 
fit.cv.bin.elastic.model_3 <-train(model_formula_3, trControl = ctrl,
                                   data = train.data.3, method = "glmnet",
                                   tuneGrid = expand.grid(alpha = seq(0.1,.2,by = 0.05),  
                                                          lambda = seq(0.05,0.3,by = 0.05)),
                                   verbose = FALSE,
                                   metric="ROC")

fit.cv.bin.elastic.model_3

elastic_model3 <- plot(fit.cv.bin.elastic.model_3, title = "Cross Validation with ElasticNet for Model 3")

cowplot::plot_grid(elastic_model2, elastic_model3)

```

```{r echo=FALSE, message=FALSE, warning = FALSE, results = "hide"}
# library(bestglm)

#train.data.covariates.1 <- train.data %>%
#  select(
#     pcos_y_n,
#     i_beta_hcg_m_iu_m_l,
#     fsh_m_iu_m_l,
#     lh_m_iu_m_l,
#     tsh_m_iu_l,
#     amh_ng_m_l ,
#     weight_gain_y_n ,
#     hair_growth_y_n,
#     skin_darkening_y_n,
#     hair_loss_y_n ,
#     pimples_y_n
#   ) %>%
#   mutate_at(c("pcos_y_n",
#               "weight_gain_y_n", 
#               "hair_growth_y_n",
#               "skin_darkening_y_n",
#               "hair_loss_y_n",
#               "pimples_y_n"),as.factor) %>%
#   mutate_at(c(
#     "i_beta_hcg_m_iu_m_l",
#     "fsh_m_iu_m_l" ,
#     "lh_m_iu_m_l" ,
#     "tsh_m_iu_l" ,
#     "amh_ng_m_l"), as.numeric)
# 
# x_tr <- train.data.covariates.1 
# # x_tr$pcos_labelled <- ifelse(x_tr$pcos_labelled=="yes",1,0)
# colnames(x_tr)[1] <- "y"
# res.bestglm <-bestglm::bestglm(Xy = x_tr,
#             family = binomial,
#             IC = "AIC",                 # Information criteria for
#             method = "exhaustive")
# 
# ## Show top 5 models
# res.bestglm$BestModels
# 
# summary(res.bestglm$BestModel)

```

### 1.4 Modelling our data using Trees and Forests 

We next pursued a Random Forest approach for our selection of variables, using both the Clinical and Clinical + Physiological Parameters for our Random Forest Modelling. Random Forest modelling was also used to examine variable importance. 

```{r echo=FALSE, message=FALSE, warning = FALSE, results = "hide"}

train.data.covariates.model2 <- train.data %>%
  select(
    pcos_y_n,
    weight_gain_y_n ,
    hair_growth_y_n,
    skin_darkening_y_n,
    hair_loss_y_n ,
    pimples_y_n
  ) %>% mutate(
  pcos_labelled = as.factor(ifelse(pcos_y_n==1, "yes", "no")))

train.data.covariates.model2

train.data.covariates.model3 <- train.data %>%
  select(
    pcos_y_n,
    i_beta_hcg_m_iu_m_l,
    fsh_m_iu_m_l ,
    lh_m_iu_m_l ,
    tsh_m_iu_l ,
    amh_ng_m_l ,
    weight_gain_y_n ,
    hair_growth_y_n,
    skin_darkening_y_n,
    hair_loss_y_n ,
    pimples_y_n
  ) %>% mutate(
  amh_ng_m_l = as.numeric(amh_ng_m_l),
  pcos_labelled = as.factor(ifelse(pcos_y_n==1, "yes", "no")))
```


Random Forest 

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)#Can also fit with caret
set.seed(504)

caret_rf_model2 <- train(
  pcos_labelled ~ .,
  data = select(train.data.covariates.model2, -pcos_y_n),                    
  method = "ranger",
  metric = "ROC",
  na.action = na.pass,
  trControl = trainControl(method = "cv", number = 5, classProbs = TRUE, summaryFunction = twoClassSummary),
  importance="impurity")

caret_rf_model3 <- train(
  pcos_labelled ~ .,
  data = select(filter(train.data.covariates.model3,!is.na(amh_ng_m_l)), -pcos_y_n),                    
  method = "ranger",
  metric = "ROC",
  na.action = na.pass,
  trControl = trainControl(method = "cv", number = 5, classProbs = TRUE, summaryFunction = twoClassSummary),
  importance="impurity"
)

knitr::kable(data.frame(
  "Model" = c("Clinical and Physiologic Model", 
              "Clinical Model"),
  "ROC"=c(mean(caret_rf_model3$resample$ROC),mean(caret_rf_model2$resample$ROC)), 
  "Sensitivity" = c(mean(caret_rf_model3$resample$Sens), mean(caret_rf_model2$resample$Sens)),
  "Specificity" = c(mean(caret_rf_model3$resample$Spec), mean(caret_rf_model2$resample$Spec)
           )))

```

```{r echo=FALSE, message=FALSE, warning = FALSE, results = "hide"}
vip::vip(caret_rf_model3)
```

# XGboost

```{r echo=FALSE, message=FALSE, warning = FALSE, results = "hide"}
set.seed(123)
xgb_grid_1  <-  expand.grid(
                  nrounds = 50,
                  eta = c(0.03),
                  max_depth = 1,
                  gamma = 0,
                  colsample_bytree = 0.6,
                  min_child_weight = 1,
                  subsample = 0.5
                )

caret_xgb_model2 <- caret::train(pcos_labelled ~., data = select(train.data.covariates.model2, -(pcos_y_n)),
                         method = "xgbTree",
                         metric = "ROC",
                         tuneGrid=xgb_grid_1,
                         na.action = na.pass,
                         trControl = trainControl(method = "cv", number = 5,classProbs = T, summaryFunction = twoClassSummary))

caret_xgb_model3 <- caret::train(pcos_labelled ~., data = select(train.data.covariates.model3, -(pcos_y_n)),
                         method = "xgbTree",
                         metric = "ROC",
                         tuneGrid=xgb_grid_1,
                         na.action = na.pass,
                         trControl = trainControl(method = "cv", number = 5,classProbs = T, summaryFunction = twoClassSummary))


```

Comparison code for later 

Data Wrangling for the test data 

```{r}

test.data.lasso <- test.data %>%
  select(
    pcos_y_n,
    i_beta_hcg_m_iu_m_l,
    fsh_m_iu_m_l,
    lh_m_iu_m_l,
    tsh_m_iu_l,
    amh_ng_m_l ,
    weight_gain_y_n ,
    hair_growth_y_n,
    skin_darkening_y_n,
    hair_loss_y_n ,
    pimples_y_n
  ) %>%
  mutate_at(c("pcos_y_n",
              "weight_gain_y_n", 
              "hair_growth_y_n",
              "skin_darkening_y_n",
              "hair_loss_y_n",
              "pimples_y_n"),as.factor) %>%
  mutate_at(c(
    "i_beta_hcg_m_iu_m_l",
    "fsh_m_iu_m_l" ,
    "lh_m_iu_m_l" ,
    "tsh_m_iu_l" ,
    "amh_ng_m_l"), as.numeric) %>%
  mutate(pcos_labelled=as.factor(ifelse(pcos_y_n==1, "yes", "no")))%>%
  select(!pcos_labelled)


test.data <- test.data %>%
  select(
    pcos_y_n,
    i_beta_hcg_m_iu_m_l,
    fsh_m_iu_m_l,
    lh_m_iu_m_l,
    tsh_m_iu_l,
    amh_ng_m_l ,
    weight_gain_y_n ,
    hair_growth_y_n,
    skin_darkening_y_n,
    hair_loss_y_n ,
    pimples_y_n
  ) %>%
  mutate_at(c("pcos_y_n",
              "weight_gain_y_n", 
              "hair_growth_y_n",
              "skin_darkening_y_n",
              "hair_loss_y_n",
              "pimples_y_n"),as.factor) %>%
  mutate_at(c(
    "i_beta_hcg_m_iu_m_l",
    "fsh_m_iu_m_l" ,
    "lh_m_iu_m_l" ,
    "tsh_m_iu_l" ,
    "amh_ng_m_l"), as.numeric) %>%
  mutate(pcos_labelled=as.factor(ifelse(pcos_y_n==1, "yes", "no")))%>%
  select(!pcos_y_n)



```



```{r include=FALSE}
model_list <- list(Random_Forest.Model3 = caret_rf_model3, XGBoost.model3 = caret_xgb_model3, 
                   Random_Forest.Model2 = caret_rf_model2, XGBoost.model2 = caret_xgb_model2
                   # , Rpart_DT = caret_tree, Bagging = caret_bag
                   )
resamples <- resamples(model_list)

#box plot
bwplot(resamples, metric="ROC")
```
```{r include=FALSE}
dotplot(resamples, metric="ROC")

```
### Evaluating on the test set 

#### Regularized Logistic Regression 

GLM Net with LASSO - Clinical Model

```{r  include=FALSE}
# prediction on Test data set
pred_rf <- stats::predict(fit.cv.bin.model2.lasso, test.data, type="prob")
# Confusion Matrix 
pred_rf$prediction <- ifelse(pred_rf$Yes < 0.5, "No", "Yes") %>% factor()
tab <- table(pred_rf$prediction, test.data$pcos_labelled)
tn <- tab[1] # TN
fn <- tab[2] # FN
fp <- tab[3] # FP
tp <- tab[4] # TP
accuracy = (tp + tn) / (tp + tn + fp + fn)
accuracy
sensitivity = tp/(tp+fn)
specificity = tn /(fp+tn)
clinical.lasso.row<-data.frame("Model"=
             "LASSO: Clinical Parameters", 
           "Accuracy"=accuracy, 
           "Sensitivity"=sensitivity, 
           "Specificity"=specificity)
```

GLM Net with LASSO - Clinical and Physiologic Model

```{r  include=FALSE}
# prediction on Test data set
pred_rf <- stats::predict(fit.cv.bin.model3.lasso, test.data, type="prob")
# Confusion Matrix 
pred_rf$prediction <- ifelse(pred_rf$Yes < 0.5, "No", "Yes") %>% factor()
tab <- table(pred_rf$prediction, test.data$pcos_labelled)
tn <- tab[1] # TN
fn <- tab[2] # FN
fp <- tab[3] # FP
tp <- tab[4] # TP
accuracy = (tp + tn) / (tp + tn + fp + fn)
accuracy
sensitivity = tp/(tp+fn)
specificity = tn /(fp+tn)
clinical.physiologic.lasso.row<-data.frame("Model"=
             "LASSO: Clinical and Physiologic Parameters", 
           "Accuracy"=accuracy, 
           "Sensitivity"=sensitivity, 
           "Specificity"=specificity)
```


#### XGBoost

XGBoost - Clinical Model 

```{r  include=FALSE}
# prediction on Test data set
pred_rf <- predict(caret_xgb_model2, test.data)
# Confusion Matrix 
xgboost.clinical <- confusionMatrix(pred_rf, test.data$pcos_labelled, positive="yes")
# Prediction Probabilities
pred_prob_rf <- predict(caret_xgb_model2, test.data, type="prob")
# ROC value
roc_rf <- pROC::roc(test.data$pcos_labelled, pred_prob_rf$yes)
# Confusion Matrix for Random Forest Model
xgboost.clinical
```

XGBoost - Clinical and Physiologic Model 

```{r  include=FALSE}
# prediction on Test data set
pred_rf <- predict(caret_xgb_model3, test.data)
# Confusion Matrix 
xgboost.clinical.physiologic <- confusionMatrix(pred_rf, test.data$pcos_labelled, positive="yes")
# Prediction Probabilities
pred_prob_rf <- predict(caret_xgb_model3, test.data, type="prob")
# ROC value
roc_rf <- pROC::roc(test.data$pcos_labelled, pred_prob_rf$yes)
# Confusion Matrix for Random Forest Model
xgboost.clinical.physiologic
```

#### Random Forest 

Random Forest - Clinical Model 

```{r  include=FALSE}
# prediction on Test data set
pred_rf <- predict(caret_rf_model2, test.data)
# Confusion Matrix 
randomForest.clinical <- confusionMatrix(pred_rf, test.data$pcos_labelled, positive="yes")
# Prediction Probabilities
pred_prob_rf <- predict(caret_rf_model2, test.data, type="prob")
# ROC value
roc_rf <- pROC::roc(test.data$pcos_labelled, pred_prob_rf$yes)
# Confusion Matrix for Random Forest Model
randomForest.clinical
```


Random Forest - Clinical and Physiologic Model 

```{r  include=FALSE}
# prediction on Test data set
pred_rf <- predict(caret_rf_model3, test.data)
# Confusion Matrix 
randomForest.clinical.physiologic <- confusionMatrix(pred_rf, test.data$pcos_labelled, positive="yes")
# Prediction Probabilities
pred_prob_rf <- predict(caret_rf_model3, test.data, type="prob")
# ROC value
roc_rf <- pROC::roc(test.data$pcos_labelled, pred_prob_rf$yes)
# Confusion Matrix for Random Forest Model
randomForest.clinical.physiologic
```

### Summarised performance

#### Table 2. Comparative performance of two models across three different modelling methodologies

```{r}

knitr::kable(
  rbind(data.frame(
  "Model"=c("Clinical Parameters: Random Forest", 
            "Clinical and Physiologic Parameters: Random Forest", 
            "Clinical Parameters: XGBoost", 
            "Clinical and Physiologic Parameters: XGBoost" 
            ), 
  "Accuracy"=c(
    randomForest.clinical$overall[1], 
    randomForest.clinical.physiologic$overall[1], 
    xgboost.clinical$overall[1], 
    xgboost.clinical.physiologic$overall[1]
  ),
  "Sensitivity"=c(
    randomForest.clinical$byClass[1], 
    randomForest.clinical.physiologic$byClass[1], 
    xgboost.clinical$byClass[1], 
    xgboost.clinical.physiologic$byClass[1]
  ), 
  "Specificity"=c(
    randomForest.clinical$byClass[2], 
    randomForest.clinical.physiologic$byClass[2], 
    xgboost.clinical$byClass[2], 
    xgboost.clinical.physiologic$byClass[2]
  )), 
  clinical.lasso.row,
  clinical.physiologic.lasso.row))
# randomForest.clinical$overall[1]

```



## 5. Discussion and Conclusions
### 5.1 Discussion

We found the best ML model which balances accuracy, specificity and clinical utility to be the Random Forest model with clinical parameters (n=5 clinical symptoms: weight gain, hair growth + skin darkening, hair loss and pimples). This model performed with the following accuracy = XX, sensitivity = XX and specificity = XX when applied to our test dataset. We opted to use a Random Forest approach as part of trying different ML models as a recent study in the literature indicating Rnadom Forest models perform the most accurately on a wide variety of datasets^6^. 

## References 

1. Teede, H., Misso, M., Tassone, E. C., Dewailly, D., Ng, E. H., Azziz, R., ... & Norman, R. J. (2018). Recommendations from the international evidence-based guideline for the assessment and management of polycystic ovary syndrome. Human Reproduction, 33(9), 1602-1618. https://doi.org/10.1093/humrep/dey256
2. Bozdag, G., Mumusoglu, S., Zengin, D., & Karabulut, E. (2016). The prevalence and phenotypic features of polycystic ovary syndrome: a systematic review and meta-analysis. Human Reproduction, 31(12), 2841–2855. https://doi.org/10.1093/humrep/dew218
3. R for Data Science by Hadley Wickham (https://r4ds.had.co.nz)
4. Ajmal N, Khan SZ, Shaikh R. Polycystic ovary syndrome (PCOS) and genetic predisposition: A review article. Eur J Obstet Gynecol Reprod Biol X. 2019 Jun 8;3:100060. doi: 10.1016/j.eurox.2019.100060. PMID: 31403134; PMCID: PMC6687436.
5. Hart R, Doherty DA. The potential implications of a PCOS diagnosis on a woman's long-term health using data linkage. J Clin Endocrinol Metab. 2015 Mar;100(3):911-9. doi: 10.1210/jc.2014-3886. Epub 2014 Dec 22. Erratum in: J Clin Endocrinol Metab. 2015 Jun;100(6):2502. PMID: 25532045.
6. Fernández-Delgado, M., Cernadas E., Barro S., Amorim D. Do we need hundreds of classifiers to solve real world classification problems? The Journal of Machine Learning Research. Volume 15. Issue 1, pp 3133–3181. 
7.
8.

## Appendix 

* Appendix Plot 1, as part of EDA, showing missing values in our dataset

```{r EDA1, echo=FALSE, fig.align = "center", fig.height=10, fig.width=10, message=FALSE, warning=FALSE, results="hide"}
# checking for missing values in dataset 
plot_missing(PCOS_data_without_infertility_formatted, title = "Plot showing missing values")

# removing the missing values from the data

PCOS_data_without_infertility_formatted <- PCOS_data_without_infertility_formatted %>%
                                              drop_na()

# view(PCOS_data_without_infertility_formatted)

```

* Appendix plot 2, as part of EDA, examining correlations between continuous features 
```{r EDA3, echo=FALSE, fig.height=10, fig.width=20, message=FALSE, warning=FALSE, results= "hide"}
# performing a correlation analysis for continuous features 
plot_correlation(PCOS_data_without_infertility_formatted, title = "Bivariate analysis to visualize our covariation between our continuous variables", theme_config = list("plot.title" = element_text(size = 24)), type = 'continuous')
```

* From this correlation plot, we find that several continuous variables do co-vary with one another.
* Specifically, as we would expect, we find a positive correlation between the variables waist and hip (in inches) with weight. We find the same positive correlation for BMI. 
* Another obvious correlation we observe is that between age (in years) and marriage (in years) 
* 

* Appendix Plot 3 showing boxplots generated to investigate potential associations between continuous variables and PCOS status. 

```{r boxplots, echo=FALSE, fig.height=10, fig.width=20, message=FALSE, warning=FALSE, results= "hide"}

plot_boxplot(PCOS_data_without_infertility_formatted, by = "pcos_y_n", title = "Boxplots for continous variables by PCOS status")



```

### Appendix Plot 4 - Univariable distributions for continuous variables  

```{r EDA2, eval=FALSE, fig.height=10, fig.width=20, message=FALSE, warning=FALSE, include=FALSE}
# plotting a histogram for each continuous feature 
plot_histogram(PCOS_data_without_infertility_formatted, theme_config = list("plot.title" = element_text(size = 24)), title = "Histograms for each continuous variable - to visualize distributions", )

```

### Appendix Section 5 - Model cross-validation (without RIDGE or LASSO) (using the caret package)
* We performed model cross-validation on our three logistic regression models and generated a summary of the cross-validation results. 

```{r echo=FALSE, message=FALSE, warning=FALSE, results = "hide"}
## cross-validation 

cv_of_data <- caret::trainControl(
  method = "repeatedcv", 
  number = 5, #five fold cross validation 
  repeats = 3 # repeat 3 times
)

set.seed(504)
# cv_of_model1 <- caret::train(
#                               pcos_y_n ~ 
#                        , 
#                               data = train.data, 
#                               method = "glm",
#                               family = "binomial",
#                               trControl = cv_of_data
#                             )



cv_of_model2 <- caret::train( pcos_y_n ~ 
                               weight_gain_y_n +
                              hair_growth_y_n +
                              skin_darkening_y_n +
                         hair_loss_y_n +
                         pimples_y_n, 
                              data = train.data, 
                              method = "glm",
                              family = "binomial",
                              trControl = cv_of_data
                            )

cv_of_model3 <- caret::train(
                              pcos_y_n ~ i_beta_hcg_m_iu_m_l + fsh_m_iu_m_l + lh_m_iu_m_l + tsh_m_iu_l + amh_ng_m_l +
                              weight_gain_y_n + hair_growth_y_n + skin_darkening_y_n + hair_loss_y_n + pimples_y_n, 
                              data = train.data, 
                              method = "glm",
                              family = "binomial",
                              trControl = cv_of_data
                            )

summary(
  resamples(
    list(
      # model1 = cv_of_model1, 
      model2 = cv_of_model2, 
      model3 = cv_of_model3
    )
  )
)$statistics$Accuracy

### Cross-validation RIDGE 

set.seed(504)
cv_of_data <- caret::trainControl(
  method = "repeatedcv", 
  number = 5, #five fold cross validation 
  repeats = 3 # repeat 3 times
)


```