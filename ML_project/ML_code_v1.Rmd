---
title: "MEDI504B_ML_Project"
author: "Jacob and Hanwei"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

``` {r libraries, echo=FALSE, message=FALSE, warning = FALSE, results = "hide"}
# loading libraries

library(tidyverse)
library(ggplot2)
library(scales)
library(finalfit)
library(patchwork)
library(readr)
library(epiR)
library(readxl)
library(gridExtra)
library(janitor)
library(ranger)
library(xgboost)
library(DataExplorer)
library(caret)

# install.packages("DataExplorer")

# install.packages("janitor")

# install.packages("ranger")

# install.packages("xgboost")


```

## 1. Introduction and Background

### 1.1 Introduction
Our overarching goal for this project is to produce a machine learning (ML) model which can accurately predict polycystic ovary syndrome (PCOS) status (presence or absence of disease). PCOS is an endocrine (hormonal) disorder that affects females of a reproductive age. Given the widespread nature of this condition and the troubling symptoms which accompany it, including infertility, it would be helpful for physicians to be able to predict individuals more likely to experience PCOS thereby enabling them to therapeutically intervene and provide care and support in a timely manner. 

### 1.2 Background 

Polycystic ovarian syndrome (PCOS) is a common endocrine disorder affecting approximately 10-15% of reproductive-age women worldwide (Teede, H., Misso, M., Tassone, E. C., Dewailly, D., Ng, E. H., Azziz, R., ... & Norman, R. J. (2018). Recommendations from the international evidence-based guideline for the assessment and management of polycystic ovary syndrome. Human Reproduction, 33(9), 1602-1618. https://doi.org/10.1093/humrep/dey256). The condition is characterized by a complex set of symptoms, including hyperandrogenism, menstrual irregularities, and polycystic ovaries (Bozdag et al., 2016). The diagnosis of PCOS is typically based on clinical and biochemical assessments, as well as ultrasound imaging of the ovaries (Teede et al., 2018). However, the diagnosis of PCOS can be challenging due to the heterogeneous presentation of symptoms and the lack of a single diagnostic criterion (Bozdag, G., Mumusoglu, S., Zengin, D., & Karabulut, E. (2016). The prevalence and phenotypic features of polycystic ovary syndrome: a systematic review and meta-analysis. Human Reproduction, 31(12), 2841â€“2855. https://doi.org/10.1093/humrep/dew218).

Machine learning models have shown promise as a potential tool for the accurate prediction of PCOS. Compared to traditional diagnostic methods, machine learning models can utilize large amounts of data from various sources and provide more accurate predictions. This is particularly beneficial in the case of PCOS, as traditional diagnostic methods such as tissue biopsy can be expensive and invasive. Furthermore, machine learning models can assist clinicians in identifying patients who may benefit from early intervention, which can improve long-term health outcomes (Teede et al., 2018).

Overall, the use of machine learning models to predict PCOS has the potential to improve the accuracy of diagnosis and reduce the cost and invasiveness of traditional diagnostic methods. We sought to evaluate the comparative accuracy of multiple machine learning classifiers to select the optimal model for predicting PCOS, given considerations surrounding false positive and false negatives. 


### Ethics
** include something about the target population and who is at risk 
** what to do if someone is pregnant --> follow up with study doctor*
** what to do if you have a suspicion that the patient is at risk for a life threatening medical disorder? 
** people taking hormone therapy
** identification of patients given the data 

Labels and predictors 



### 1.3 Data

The dataset consists of physical and clinical parameters collected from 10 hospitals across Kerala, India, to determine PCOS and infertility-related issues.  The dataset contains information that can be used to analyze and understand the diagnosis and treatment of PCOS and infertility.


## 2. Objectives

Our objectives were twofold: 

1: Develop a simple model that can predict PCOS status using clinical and physiologic data that can be acquired using a routine blood test and assessment by a general practitioner clinician. 

2: Optimize the model for specificity, thus minimizing the risk of a false positive in model predictions. 

The rationale for objective one was based on the motivation to provide a data-based method of diagnosis that is cheaper and less invasive than current methods. As discussed in the background section of this report, current diagnosis of PCOS can be time-consuming and invasive, and replacing these methods with a model is advantaegous for reasons related to clinical care and resource utilization. This influenced our variable selection, as we did not consider the inclusion of predictors that can not be measured in the above stated context in model development. 

Optimizing model specificity for the prediction of PCOS is important because PCOS is associated with several negative health outcomes, including infertility, insulin resistance, and metabolic disorders. Early diagnosis and treatment of PCOS can help prevent or manage these conditions, which can ultimately improve the overall health and quality of life of those affected. However, given that PCOS is not a life-threatening condition in and of itself, it is important to balance the trade-off between maximizing sensitivity and specificity in order to minimize the number of false positives and prevent unnecessary and potentially invasive follow-up testing. By optimizing model specificity, we can ensure that those who are diagnosed with PCOS are more likely to truly have the condition, while also reducing the risk of unnecessary medical interventions for those who do not have PCOS.

## 3. Methods

### 3.1 Splitting our dataset into training and testing datasets
Following our EDA (please refer to EDA section), we start by splitting our dataset into the training set and the validation set, followed by building a simple model aimed at using our data to find factors that predict PCOS status (our outcome variable). We chose to partition our data into only two sets based on the relatively small overall sample size of our data and small effective sample size of our data. Further, to help determine generalizability, we believe it would be ideal for our predictive model to be validated on an external dataset derived from a different population than our training and test data.  

### 3.2 Building logistic regression models 

We first attempted to model our data with PCOS status as the outcome variable using three different logistic regression models. At this stage of variable selection, we relied on the Akaike Information Criteria (AIC) to assess model fit. Of the tested logistic regression models, we prespecified that we would select the model with the lowest AIC. The three tested models utilized the following construction:

* (1) Model 1 included all the features in our dataset
* (2) Model 2 only includes physiological variables we think are of interest in PCOS, namely the hormone measurements (n=5 different types of hormones)
* (3) Model 3 includes the n=5 the hormone measurement levels we in our dataset, and in addition to these features, the clinical symptoms that have been known to be associated with PCOS: weight gain, hair growth + skin darkening, hair loss and pimples. 

Of our three logistic regression models, Model 3 had the lowest AIC score of 566.45. We also assessed autocorrelation and collinearity among the variables in model three. *NEED TO ADD*

## Results 

## 4. Results

## 4a. Exploratory Data Analysis
This section contains the steps and output for the EDA performed on the PCOS dataset. The section proceeds sequentially with each step of EDA. Please refer to bullet points, figure titles and figure captions for more details. The first steps in our EDA involved getting a high-level overview of our dataset and determining the dimension of our data: n=541 rows and n=45 columns. Further checking of the dataset reveals an additional column (column 45). This column does not contain any useful information and is not one of our 44 features, therefore the column was removed. We find that our dataset has the following variables: Sl. No, Patient File No., PCOS (Y/N), Age (yrs), Weight (Kg), Height(Cm), BMI, Blood Group, Pulse rate(bpm), RR(breaths/min), Hb(g/dl), Cycle(R/I), Cycle length(days), Marriage Status (Yrs), Pregnant(Y/N), No. of aborptions, I   beta-HCG(mIU/mL), II    beta-HCG(mIU/mL), FSH(mIU/mL), LH(mIU/mL), FSH/LH, Hip(inch), Waist(inch), Waist:Hip Ratio, TSH (mIU/L), AMH(ng/mL), PRL(ng/mL), Vit D3 (ng/mL), PRG(ng/mL), RBS(mg/dl), Weight gain(Y/N), hair growth(Y/N), Skin darkening (Y/N), Hair loss(Y/N), Pimples(Y/N), Fast food (Y/N), Reg.Exercise(Y/N), BP _Systolic (mmHg), BP _Diastolic (mmHg), Follicle No. (L), Follicle No. (R), Avg. F size (L) (mm), Avg. F size (R) (mm), Endometrium (mm).

``` {r loading, echo=FALSE, message=FALSE, warning = FALSE, results = "hide"}
# loading data
# setwd("/Users/hanweisudderuddin/Desktop/MSc Stuff/Classes/MEDI504B/Week1_lab_EDA")
setwd(here::here())
# PCOS_infertility <- read_csv("PCOS_infertility.csv")
data_loc <- here::here()
# reading in PCOS_data_without_infertility from excel file
PCOS_data_without_infertility <-read_excel(paste0(data_loc, "/PCOS_data_without_infertility.xlsx"), sheet = "Full_new")
# PCOS_infertility <- read_csv("PCOS_infertility.csv")



# glimpse(PCOS_data_without_infertility)

# view(PCOS_data_without_infertility)

# summary(PCOS_data_without_infertility)

```

```{r cleaning, echo=FALSE, fig.height=10, fig.width=20, message=FALSE, warning=FALSE, results= "hide"}
## checking and cleaning dataset 
unique(PCOS_data_without_infertility$...45)

## removing column "...45" to clean dataset

PCOS_data_without_infertility <- PCOS_data_without_infertility %>%
                                    select(-...45)

# glimpse(PCOS_data_without_infertility)

# view(PCOS_data_without_infertility)

## cleaning variable names with janitor package

PCOS_data_without_infertility_cleaned <- PCOS_data_without_infertility %>%
                                          clean_names()

# glimpse(PCOS_data_without_infertility_cleaned)

```

### 4a.1 Data Wrangling

The data was formatted to ensure the variables are the appropriate class type, this will enable us to perform our EDA. Specifically we converted binary variables (1 or 0) into the character class type.Next in our EDA we sought to identify missing values in our dataset. Here, we see a plot showing our variables and the percentage of missing rows per variable. The plot shows the missing values in our dataset. Our EDA identified some missing values for two variables: fast food and marriage status. The analysis indicates that only 0.18% of the rows for these variables are missing. Therefore, as this is below the generally used threshold of 5 %, missing values were simply removed for our subsequent analyses. 

```{r formatting, echo=FALSE, fig.height=10, fig.width=20, message=FALSE, warning=FALSE, results="hide"}
## ensuring variables are in the correct format 

PCOS_data_without_infertility_formatted <- PCOS_data_without_infertility_cleaned %>%
                                              mutate_at(c("sl_no",
                                                          "patient_file_no",
                                                          "pcos_y_n",
                                                          "weight_gain_y_n", 
                                                          "hair_growth_y_n",
                                                          "hair_growth_y_n",
                                                          "skin_darkening_y_n",
                                                          "hair_loss_y_n",
                                                          "pimples_y_n",
                                                          "fast_food_y_n",
                                                          "reg_exercise_y_n"), as.character)

# glimpse(PCOS_data_without_infertility_formatted)

```


### 4a.2 Bivariate associations 

We examined associations for categorical predictors and the outcome (PCOS) by constructing bivariate plots for the predictors stratified by PCOS status. 

```{r EDA4, echo=FALSE, fig.height=10, fig.width=20, message=FALSE, warning=FALSE, results= "hide"}
# plotting bar plots for each categorical feature
plot_bar(PCOS_data_without_infertility_formatted, by = "pcos_y_n", title = "Barplots for the categorical variables in our dataset")

```

From the figure, we can see that the proportion of individuals with weight gain and a positive PCOS status is greater than the proportion of individuals with no weight gain and a positive PCOS status. We observe similar associations for hair growth and skin darkening. We also observe a similar but much weaker association for the categorical variables of hair loss and pimples. Interestingly, we observe the inverse trend for the categorical variable for fast food consumption. As these predictors appear to be visually associated with the outcome, as well as physiologically feasible to be associated with PCOS, they should be considered for inclusion in the predictive model. 

The bar plots for regular exercise and pregnancy do not appear to show a signfiicant difference in proportion of positive PCOS cases, but we would need to perform a statistical analyses (such as an unpaired t-test) to know for sure. 
To ascertain the relationship between PCOS status and continuous predictors, we also plotted boxplots to visualize any associations between PCOS status and a continuous variable. Please refer to the appendix for these boxplots.

For this section of the EDA, we looked more closely at the relationships between selected variables and our outcome variable of interest (for this project: yes or no for PCOS), based on how our boxplots looked initially (please refer to Appendix for all boxplots) and on some knowledge gained via our literature survey, we will highlight the relatiionship of select variables with our outcome variable (PCOS status). While the etiology for PCOS is not known, our literature survey suggests PCOS is associated with abnormal hormone levels. Thus, to look into this further as part of the EDA, we compared measurements of hormone levels and PCOS status to get a sense of the relationships between these variables.

### Boxplots looking at relationship of hormones and PCOS status
```{r hormonevariables, echo=FALSE, fig.height=10, fig.width=20, message=FALSE, warning=FALSE, results= "hide"}

## looking more closely and the relationships between selected variables and our outcome variable of interest (PCOS yes or no)

## I   beta-HCG(mIU/mL) hormone 

# glimpse(PCOS_data_without_infertility_formatted)

eda_compare_plot1 <- PCOS_data_without_infertility_formatted %>%
                        ggplot(aes(pcos_y_n, i_beta_hcg_m_iu_m_l)) + 
                        geom_boxplot() +
                        theme_bw() +
                        theme(title = element_text(size = 22),
                              plot.caption = element_text(hjust = 0, size = 20)) +
                        labs(title = "Beta-HCG and PCOS status") + scale_y_log10() 

# eda_compare_plot1


## follicle stimulating hormone

eda_compare_plot2 <- PCOS_data_without_infertility_formatted %>%
                        ggplot(aes(pcos_y_n, fsh_m_iu_m_l)) + 
                        geom_boxplot() +
                        theme_bw() +
                        theme(title = element_text(size = 22),
                              plot.caption = element_text(hjust = 0, size = 20)) +
                        labs(title = "Follicle stimulating hormone and PCOS status") +
                        scale_y_log10()

# eda_compare_plot2


## luteinizing hormone

eda_compare_plot3 <- PCOS_data_without_infertility_formatted %>%
                        ggplot(aes(pcos_y_n, lh_m_iu_m_l)) + 
                        geom_boxplot() +
                        theme_bw() +
                        theme(title = element_text(size = 22),
                              plot.caption = element_text(hjust = 0, size = 20)) +
                        labs(title = "Luteinizing hormone and PCOS status") +
                        scale_y_log10()

# eda_compare_plot4

## Thyroid Stimulating Hormone

eda_compare_plot4 <- PCOS_data_without_infertility_formatted %>%
                        ggplot(aes(pcos_y_n,tsh_m_iu_l)) + 
                        geom_boxplot() +
                        theme_bw() +
                        theme(title = element_text(size = 22),
                              plot.caption = element_text(hjust = 0, size = 20)) +
                        labs(title = "Thyroid Stimulating Hormone and PCOS status") +
                        scale_y_log10()

# eda_compare_plot4


cowplot::plot_grid(eda_compare_plot1, eda_compare_plot2, eda_compare_plot3, eda_compare_plot4, ncol=2, nrow=2)
```

<!-- * From the literature, we know that PCOS diagnosis often involves an ultrasound and endometrium thickness is measured as part of this process. Therefore, as part of our EDA, we also sought to look at the relationship between endometrium thickness and PCOS status.  -->

<!-- ```{r endothicknessvariable, echo=FALSE, fig.height=10, fig.width=20, message=FALSE, warning=FALSE, results= "hide"} -->
<!-- ## thickness of endometrium and PCOS -->
<!-- PCOS_data_without_infertility_formatted -->

<!-- eda_compare_plot5 <- PCOS_data_without_infertility_formatted %>% -->
<!--                         ggplot(aes(pcos_y_n, -->
<!--                                    endometrium_mm)) +  -->
<!--                         geom_boxplot() + -->
<!--                         theme_bw() + -->
<!--                         labs(title = "Exploring relationship between Endometrium thickness and PCOS status") + -->
<!--                         scale_y_log10() -->

<!-- eda_compare_plot5 -->

<!-- ##  -->

<!-- ``` -->

<!-- * From this series of boxplots, we did not observe (visually) any significant difference in the association of PCOS status and hormone levels. However, given what we know about the association of PCOS and hormone imbalances from the literature, I think it would still be useful to include these variables when we build our model.  -->

* From the literature^2^, there is also evidence that miscarriages are associated with PCOS. Therefore, as part of our EDA, we sought to look at the relationship between PCOS status and number of abortions. 


### Modelling

```{r methods, echo=FALSE, message=FALSE, warning = FALSE, results = "hide"}

# loading data
# setwd("/Users/hanweisudderuddin/Desktop/MSc Stuff/Classes/MEDI504B/Week1_lab_EDA")
setwd(here::here())
# PCOS_infertility <- read_csv("PCOS_infertility.csv")
data_loc <- here::here()
# reading in PCOS_data_without_infertility from excel file
PCOS_data_without_infertility <-read_excel(paste0(data_loc, "/PCOS_data_without_infertility.xlsx"), sheet = "Full_new")

## checking and cleaning dataset 
unique(PCOS_data_without_infertility$...45)

## removing column "...45" to clean dataset

PCOS_data_without_infertility <- PCOS_data_without_infertility %>%
                                    select(-...45)

# glimpse(PCOS_data_without_infertility)

# view(PCOS_data_without_infertility)

## cleaning variable names with janitor package

PCOS_data_without_infertility_cleaned <- PCOS_data_without_infertility %>%
                                          clean_names()

glimpse(PCOS_data_without_infertility_cleaned)

PCOS_data_without_infertility_formatted <- PCOS_data_without_infertility_cleaned %>%
                                              mutate_at(c("sl_no",
                                                          "patient_file_no",
                                                          "pcos_y_n",
                                                          "weight_gain_y_n", 
                                                          "hair_growth_y_n",
                                                          "hair_growth_y_n",
                                                          "skin_darkening_y_n",
                                                          "hair_loss_y_n",
                                                          "pimples_y_n",
                                                          "fast_food_y_n",
                                                          "reg_exercise_y_n"), as.factor)

glimpse(PCOS_data_without_infertility_formatted)

PCOS_data_without_infertility_formatted_final <- PCOS_data_without_infertility_formatted %>%
                                              drop_na()

unique(PCOS_data_without_infertility_formatted_final$pcos_y_n)

# changing outcome variable to factor class 
PCOS_data_without_infertility_formatted_final$pcos_y_n <- as.factor(PCOS_data_without_infertility_formatted_final$pcos_y_n)
```

```{r, data split, echo=FALSE, message=FALSE, warning = FALSE, results = "hide"}
#####
## setting the seed (enables randomization in a reproducible way)
set.seed(504)

data_split <- caret::createDataPartition(PCOS_data_without_infertility_formatted_final$pcos_y_n, p=0.7, list= FALSE)

train.data <- PCOS_data_without_infertility_formatted_final[data_split,]
# dim(train.data)
test.data <- PCOS_data_without_infertility_formatted_final[-data_split,]
# dim(test.data)

# table(train.data$pcos_y_n)

# the first model we will build will include all the variables 
#library(glmnet)

logistic_model1 <- glm(pcos_y_n ~               
                         i_beta_hcg_m_iu_m_l +
                         fsh_m_iu_m_l + 
                         lh_m_iu_m_l + 
                         tsh_m_iu_l +
                         amh_ng_m_l,
                       data = train.data,
                       family = binomial(link="logit")) 


# AIC = 758
# removed this as not super informative for logistic models 
# plot(logistic_model1)

library(broom)

# the second model uses clinical data only

logistic_model2 <-glm(pcos_y_n ~ 
                          weight_gain_y_n +
                         hair_growth_y_n +
                         skin_darkening_y_n +
                         hair_loss_y_n +
                         pimples_y_n,
                      data = train.data,
                      family = binomial(link="logit"))


# AIC = 609.28

# glimpse(PCOS_data_without_infertility_formatted_final)

# the third model we will build will include the following variables:
# 5 of the hormone measurement levels we possess
# as well as the following physiological variables (as these are clinical symptoms associated with PCOS): 

logistic_model3 <- glm(pcos_y_n ~ 
                         i_beta_hcg_m_iu_m_l +
                         fsh_m_iu_m_l + 
                         lh_m_iu_m_l + 
                         tsh_m_iu_l +
                         amh_ng_m_l +
                         weight_gain_y_n +
                         hair_growth_y_n +
                         skin_darkening_y_n +
                         hair_loss_y_n +
                         pimples_y_n,
                       data = train.data,
                       family = binomial(link="logit"))


# AIC = 566.45

auc1 <- pROC::roc(train.data$pcos_y_n,
                   fitted(logistic_model1))
tidyr::extract_numeric(auc1$auc)
auc2 <- pROC::roc(train.data$pcos_y_n,
                   fitted(logistic_model2))
tidyr::extract_numeric(auc2$auc)
auc3 <- pROC::roc(train.data$pcos_y_n,
                   fitted(logistic_model3))
tidyr::extract_numeric(auc3$auc)

knitr::kable(data.frame("Model"=c("Physiologic Model", "Clinical Model", "Physiologic and Clinical Model"),
           "AIC"=c(logistic_model1$aic, logistic_model2$aic, logistic_model3$aic), 
           "ROC"=c(tidyr::extract_numeric(auc1$auc), tidyr::extract_numeric(auc2$auc), tidyr::extract_numeric(auc3$auc)
)))
# 
# BIC(logistic_model1)
# BIC(logistic_model2)
# BIC(logistic_model3)


```

Based on these results, we will compare the clinical model to the full clinical and physiological model. While the model including clinical predictors only is more simple both technically (as evidenced by the AIC) and practically (less inputs and no blood testing required), there is an approximately 10% drop in accuracy when excluding the phsyiologic data. We will select these two models and compare performance in applying various machine learning methods below. 

### 3.3 Model cross-validation (without RIDGE or LASSO) (using the caret package)
* We performed model cross-validation on our three logistic regression models and generated a summary of the cross-validation results. 

```{r echo=FALSE, message=FALSE, warning=FALSE}
## cross-validation 

cv_of_data <- caret::trainControl(
  method = "repeatedcv", 
  number = 5, #five fold cross validation 
  repeats = 3 # repeat 3 times
)

set.seed(504)
cv_of_model1 <- caret::train(
                              pcos_y_n ~ ., 
                              data = train.data, 
                              method = "glm",
                              family = "binomial",
                              trControl = cv_of_data
                            )



set.seed(504)
cv_of_model2 <- caret::train(
                              pcos_y_n ~ i_beta_hcg_m_iu_m_l + fsh_m_iu_m_l + lh_m_iu_m_l + tsh_m_iu_l + amh_ng_m_l, 
                              data = train.data, 
                              method = "glm",
                              family = "binomial",
                              trControl = cv_of_data
                            )

set.seed(504)
cv_of_model3 <- caret::train(
                              pcos_y_n ~ i_beta_hcg_m_iu_m_l + fsh_m_iu_m_l + lh_m_iu_m_l + tsh_m_iu_l + amh_ng_m_l +
                              weight_gain_y_n + hair_growth_y_n + skin_darkening_y_n + hair_loss_y_n + pimples_y_n, 
                              data = train.data, 
                              method = "glm",
                              family = "binomial",
                              trControl = cv_of_data
                            )

summary(
  resamples(
    list(
      model1 = cv_of_model1, 
      model2 = cv_of_model2, 
      model3 = cv_of_model3
    )
  )
)$statistics$Accuracy

### Cross-validation RIDGE 

set.seed(504)
cv_of_data <- caret::trainControl(
  method = "repeatedcv", 
  number = 5, #five fold cross validation 
  repeats = 3 # repeat 3 times
)


```

### 3.4 Assessing model classification performance 
* Assessing model performance using ROC curves 

```{r echo=FALSE, fig.height=8, fig.width=4, message=FALSE, warning=FALSE}
## plotting ROC and AUC 

plot(pROC::roc(train.data$pcos_y_n,
                   fitted(logistic_model1)),
               col = "red", 
               main = "ROC curves: model 1 (red) vs. model 2 (blue) \n vs. model 3 (green)")
plot(pROC::roc(train.data$pcos_y_n,
                   fitted(logistic_model2)),
               print.auc = T, 
               col = "blue", 
               add = T, 
                print.auc.y = .6)
plot(pROC::roc(train.data$pcos_y_n,
                   fitted(logistic_model3)),
               print.auc = T, 
               col = "green", 
               add = T,
     print.auc.y=.4)

```

### Penalized logistic regression with cross-validation (RIDGE and LASSO)

```{r eval=FALSE, include=FALSE}

glimpse(train.data)

summary(train.data)

train.data.covariates.all <- train.data %>% 
                                 mutate(pcos_y_n = ifelse(pcos_y_n == "1", "Yes", "No")) %>%
                                 drop_na()

glimpse(train.data.covariates.all)

baselinevars_all <- names(dplyr::select(train.data.covariates.all, 
                         !c(pcos_y_n)))
baselinevars_all

model_formula_all <- as.formula(paste("pcos_y_n~ ", 
                               paste(baselinevars_all, 
                                     collapse = "+")))

model_formula_all

train.data.2 <- train.data.covariates.all %>%
                  select(pcos_y_n,
                         i_beta_hcg_m_iu_m_l,
                         fsh_m_iu_m_l,
                         lh_m_iu_m_l,
                         tsh_m_iu_l ,
                         amh_ng_m_l)

glimpse(train.data.2)

train.data.covariates.1 <- train.data %>%
  select(
    pcos_y_n,
    i_beta_hcg_m_iu_m_l,
    fsh_m_iu_m_l,
    lh_m_iu_m_l,
    tsh_m_iu_l,
    amh_ng_m_l ,
    weight_gain_y_n ,
    hair_growth_y_n,
    skin_darkening_y_n,
    hair_loss_y_n ,
    pimples_y_n
  ) %>%
  mutate_at(c("pcos_y_n",
              "weight_gain_y_n", 
              "hair_growth_y_n",
              "skin_darkening_y_n",
              "hair_loss_y_n",
              "pimples_y_n"),as.factor) %>%
  mutate_at(c(
    "i_beta_hcg_m_iu_m_l",
    "fsh_m_iu_m_l" ,
    "lh_m_iu_m_l" ,
    "tsh_m_iu_l" ,
    "amh_ng_m_l"), as.numeric) 

# train.data.2 <- train.data.covariates.1 %>%
#                  drop_na() %>%
#                  mutate(pcos_y_n = ifelse(pcos_y_n == "1", "Yes", "No"))

glimpse(train.data.2)

train.data.3 <- train.data.covariates.1 %>%
                  drop_na() %>%
                  mutate(pcos_y_n = ifelse(pcos_y_n == "1", "Yes", "No"))

# view(train.data.1)

# summary(train.data.1)

baselinevars_3 <- names(dplyr::select(train.data.3, 
                         !c(pcos_y_n)))
baselinevars_3

model_formula_3 <- as.formula(paste("pcos_y_n~ ", 
                               paste(baselinevars_3, 
                                     collapse = "+")))

model_formula_3

## RIDGE cross-validation of our logistic regression models (with binary outcome)
set.seed(504)
ctrl<-trainControl(method = "cv", number = 5,
                   classProbs = TRUE,
                   summaryFunction = twoClassSummary)


## model 1 with all variables
fit.cv.bin.model.all <-train(model_formula_all, trControl = ctrl,
                                 data = train.data.covariates.all, method = "glmnet",
                                 lambda= 0,
                                 tuneGrid = expand.grid(alpha = 0,  
                                                        lambda = 0),
                                 verbose = FALSE,
                                 metric="ROC")
fit.cv.bin.model.all

# model 1 ROC output (RIDGE): 0.5662222

## model 2 with only hormone variables 
fit.cv.bin.model2 <-train(pcos_y_n ~ ., trControl = ctrl,
                                 data = train.data.2, method = "glmnet",
                                 lambda= 0,
                                 tuneGrid = expand.grid(alpha = 0,  
                                                        lambda = 0),
                                 verbose = FALSE,
                                 metric="ROC")
fit.cv.bin.model2

# model 2 ROC output (RIDGE): 0.6045425

## model 3 with hormone variables and clinical symptoms 
fit.cv.bin.model3 <-train(model_formula_3, trControl = ctrl,
                                 data = train.data.3, method = "glmnet",
                                 lambda= 0,
                                 tuneGrid = expand.grid(alpha = 0,  
                                                        lambda = 0),
                                 verbose = FALSE,
                                 metric="ROC")
fit.cv.bin.model3
# model 3 ROC output (RIDGE): 0.8737665

## LASSO cross-validation of our logistic regression models

set.seed(504)
ctrl<-trainControl(method = "cv", number = 5,
                   classProbs = TRUE,
                   summaryFunction = twoClassSummary)


## model 1 with all variables
fit.cv.bin.model.all.lasso <-train(model_formula_all, trControl = ctrl,
                                 data = train.data.covariates.all, method = "glmnet",
                                 lambda= 0,
                                 tuneGrid = expand.grid(alpha = 1,  
                                                        lambda = 0),
                                 verbose = FALSE,
                                 metric="ROC")
fit.cv.bin.model.all.lasso

# model 1 output (LASSO): 0.6005752

## model 2 with only hormone variables 
fit.cv.bin.model2.lasso <-train(pcos_y_n ~ ., trControl = ctrl,
                                 data = train.data.2, method = "glmnet",
                                 lambda= 0,
                                 tuneGrid = expand.grid(alpha = 1,  
                                                        lambda = 0),
                                 verbose = FALSE,
                                 metric="ROC")
fit.cv.bin.model2.lasso

# model 2 output (LASSO): 0.6286078

## model 3 with hormone variables and clinical symptoms 
fit.cv.bin.model3.lasso <-train(model_formula_3, trControl = ctrl,
                                 data = train.data.3, method = "glmnet",
                                 lambda= 0,
                                 tuneGrid = expand.grid(alpha = 1,  
                                                        lambda = 0),
                                 verbose = FALSE,
                                 metric="ROC")

fit.cv.bin.model3.lasso

# model 3 output (LASSO): 0.8756765

## Cross-validation using ElasticNet

# CV using ElasticNet (for model 1)
set.seed(504)
ctrl<-trainControl(method = "cv", number = 5,
                   classProbs = TRUE,
                   summaryFunction = twoClassSummary)

fit.cv.bin.elastic.model_1 <-train(model_formula_all, trControl = ctrl,
                                   data = train.data.covariates.all, method = "glmnet",
                                   tuneGrid = expand.grid(alpha = seq(0.1,.2,by = 0.05),  
                                                          lambda = seq(0.05,0.3,by = 0.05)),
                                   verbose = FALSE,
                                   metric="ROC")

fit.cv.bin.elastic.model_1

elastic_model1 <- plot(fit.cv.bin.elastic.model_1)

# CV using ElasticNet (for model 2) 

fit.cv.bin.elastic.model_2 <-train(pcos_y_n ~ ., trControl = ctrl,
                                   data = train.data.2, method = "glmnet",
                                   tuneGrid = expand.grid(alpha = seq(0.1,.2,by = 0.05),  
                                                          lambda = seq(0.05,0.3,by = 0.05)),
                                   verbose = FALSE,
                                   metric="ROC")

elastic_model2 <- plot(fit.cv.bin.elastic.model_2)

# CV using ElasticNet (for model 3) 
fit.cv.bin.elastic.model_3 <-train(model_formula_3, trControl = ctrl,
                                   data = train.data.3, method = "glmnet",
                                   tuneGrid = expand.grid(alpha = seq(0.1,.2,by = 0.05),  
                                                          lambda = seq(0.05,0.3,by = 0.05)),
                                   verbose = FALSE,
                                   metric="ROC")

fit.cv.bin.elastic.model_3

elastic_model3 <- plot(fit.cv.bin.elastic.model_3)

elastic_model3

```

```{r}
# library(bestglm)

#train.data.covariates.1 <- train.data %>%
#  select(
#     pcos_y_n,
#     i_beta_hcg_m_iu_m_l,
#     fsh_m_iu_m_l,
#     lh_m_iu_m_l,
#     tsh_m_iu_l,
#     amh_ng_m_l ,
#     weight_gain_y_n ,
#     hair_growth_y_n,
#     skin_darkening_y_n,
#     hair_loss_y_n ,
#     pimples_y_n
#   ) %>%
#   mutate_at(c("pcos_y_n",
#               "weight_gain_y_n", 
#               "hair_growth_y_n",
#               "skin_darkening_y_n",
#               "hair_loss_y_n",
#               "pimples_y_n"),as.factor) %>%
#   mutate_at(c(
#     "i_beta_hcg_m_iu_m_l",
#     "fsh_m_iu_m_l" ,
#     "lh_m_iu_m_l" ,
#     "tsh_m_iu_l" ,
#     "amh_ng_m_l"), as.numeric)
# 
# x_tr <- train.data.covariates.1 
# # x_tr$pcos_labelled <- ifelse(x_tr$pcos_labelled=="yes",1,0)
# colnames(x_tr)[1] <- "y"
# res.bestglm <-bestglm::bestglm(Xy = x_tr,
#             family = binomial,
#             IC = "AIC",                 # Information criteria for
#             method = "exhaustive")
# 
# ## Show top 5 models
# res.bestglm$BestModels
# 
# summary(res.bestglm$BestModel)

```

### 1.4 Modelling our data using Trees and Forests 

Let's select only the predictor columns we decided we wanted to include earlier. 
From logistic model 3, here is the list of covariates: 
* pcos_y_n 
* i_beta_hcg_m_iu_m_l
* fsh_m_iu_m_l 
* lh_m_iu_m_l 
* tsh_m_iu_l
* amh_ng_m_l 
* weight_gain_y_n
* hair_growth_y_n
* skin_darkening_y_n 
* hair_loss_y_n 
* pimples_y_n

```{r}
train.data.covariates <- train.data %>%
  select(
    pcos_y_n,
    i_beta_hcg_m_iu_m_l,
    fsh_m_iu_m_l ,
    lh_m_iu_m_l ,
    tsh_m_iu_l ,
    amh_ng_m_l ,
    weight_gain_y_n ,
    hair_growth_y_n,
    skin_darkening_y_n,
    hair_loss_y_n ,
    pimples_y_n
  ) %>% mutate(
  amh_ng_m_l = as.numeric(amh_ng_m_l),
  pcos_labelled = as.factor(ifelse(pcos_y_n==1, "yes", "no")))
```


Random Forest -- note that I've had to remove one missing ob from amh_ng_m_l for now. 

```{r echo=FALSE, message=FALSE, warning=FALSE}
#Can also fit with caret
set.seed(123)
caret_rf <- train(
  pcos_labelled ~ .,
  data = select(filter(train.data.covariates,!is.na(amh_ng_m_l)), -pcos_y_n),                    
  method = "ranger",
  metric = "ROC",
  na.action = na.pass,
  trControl = trainControl(method = "cv", number = 5, classProbs = TRUE, summaryFunction = twoClassSummary),
  importance="impurity"
)
```

RF Variable Importance 

```{r}
vip::vip(caret_rf)
```

# XGboost

```{r}
set.seed(123)
xgb_grid_1  <-  expand.grid(
                  nrounds = 50,
                  eta = c(0.03),
                  max_depth = 1,
                  gamma = 0,
                  colsample_bytree = 0.6,
                  min_child_weight = 1,
                  subsample = 0.5
                )

caret_xgb <- caret::train(pcos_labelled ~., data = select(train.data.covariates, -(pcos_y_n)),
                         method = "xgbTree",
                         metric = "ROC",
                         tuneGrid=xgb_grid_1,
                         na.action = na.pass,
                         trControl = trainControl(method = "cv", number = 5,classProbs = T, summaryFunction = twoClassSummary))
caret_xgb

```

Comparison code for later 

```{r eval=FALSE, include=FALSE}
model_list <- list(Random_Forest = caret_rf, XGBoost = caret_xgb, Rpart_DT = caret_tree, Bagging = caret_bag)
resamples <- resamples(model_list)

#box plot
bwplot(resamples, metric="ROC")
```
```{r eval=FALSE, include=FALSE}
dotplot(resamples, metric="ROC")

```
```{r eval=FALSE, include=FALSE}
# prediction on Test data set
pred_rf <- predict(caret_rf, valid)

# Confusion Matrix 
cm_rf <- confusionMatrix(pred_rf, valid$diabetes, positive="pos")

# Prediction Probabilities
pred_prob_rf <- predict(caret_rf, valid, type="prob")

# ROC value
roc_rf <- pROC::roc(valid$diabetes, pred_prob_rf$pos)

# Confusion Matrix for Random Forest Model
cm_rf
```


## 5. Discussion and Conclusions
### 5.1 Discussion

* Ethics statement 

## References 

1. R for Data Science by Hadley Wickham (https://r4ds.had.co.nz)
2. Ajmal N, Khan SZ, Shaikh R. Polycystic ovary syndrome (PCOS) and genetic predisposition: A review article. Eur J Obstet Gynecol Reprod Biol X. 2019 Jun 8;3:100060. doi: 10.1016/j.eurox.2019.100060. PMID: 31403134; PMCID: PMC6687436.

## Appendix 

* Appendix Plot 1, as part of EDA, showing missing values in our dataset

```{r EDA1, echo=FALSE, fig.align = "center", fig.height=10, fig.width=10, message=FALSE, warning=FALSE, results="hide"}
# checking for missing values in dataset 
plot_missing(PCOS_data_without_infertility_formatted, title = "Plot showing missing values")

# removing the missing values from the data

PCOS_data_without_infertility_formatted <- PCOS_data_without_infertility_formatted %>%
                                              drop_na()

# view(PCOS_data_without_infertility_formatted)

```

* Appendix plot 2, as part of EDA, examining correlations between continuous features 
```{r EDA3, echo=FALSE, fig.height=10, fig.width=20, message=FALSE, warning=FALSE, results= "hide"}
# performing a correlation analysis for continuous features 
plot_correlation(PCOS_data_without_infertility_formatted, title = "Bivariate analysis to visualize our covariation between our continuous variables", theme_config = list("plot.title" = element_text(size = 24)), type = 'continuous')
```



* From this correlation plot, we find that several continuous variables do co-vary with one another.
* Specifically, as we would expect, we find a positive correlation between the variables waist and hip (in inches) with weight. We find the same positive correlation for BMI. 
* Another obvious correlation we observe is that between age (in years) and marriage (in years) 
* 

* Appendix Plot 3 showing boxplots generated to investigate potential associations between continuous variables and PCOS status. 

```{r boxplots, echo=FALSE, fig.height=10, fig.width=20, message=FALSE, warning=FALSE, results= "hide"}

plot_boxplot(PCOS_data_without_infertility_formatted, by = "pcos_y_n", title = "Boxplots for continous variables by PCOS status")



```

### 4a.2 Univariable distributions for continuous variables  

To get a sense of the variation in our dataset, we plotted histograms for each continuous variable using the plot_histogram() from the DataExplorer Package. 

```{r EDA2, eval=FALSE, fig.height=10, fig.width=20, message=FALSE, warning=FALSE, include=FALSE}
# plotting a histogram for each continuous feature 
plot_histogram(PCOS_data_without_infertility_formatted, theme_config = list("plot.title" = element_text(size = 24)), title = "Histograms for each continuous variable - to visualize distributions", )

```

We see that the age distribution in our dataset reveals most individuals are in the range of 20 to 40 years. No individuals in the dataset are younger than 20 or older than 50. As we would expect, the BMI values follow an approximately normal distribution. The most common blood type we observe is O+, which is consistent with the fact that O+ is the most frequent bloodtype globally. The most common cycle length is 5 days. The endometrium thickness data suggests there are two most most common thickness values (two clear peaks in the distribution). 

